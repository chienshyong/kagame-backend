{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Summary:\n",
      "Total products found: 85\n",
      "Successfully processed: 85\n",
      "Skipped products: 0\n",
      "\n",
      "\n",
      "Saved valid products to products.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_uniqlo(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    products = []\n",
    "    errors = []\n",
    "    \n",
    "    product_cards = soup.find_all('article', class_='_13lwRUB5FbvQg2uaUeYNJ9')\n",
    "    \n",
    "    for index, card in enumerate(product_cards):\n",
    "        product_data = {}\n",
    "        try:\n",
    "            # Track product name early for error reporting\n",
    "            name_element = card.find('h3', class_='product-tile-product-description')\n",
    "            product_name = name_element.text.strip() if name_element else \"Unknown Product\"\n",
    "            \n",
    "            # 1. Validate name\n",
    "            if not name_element:\n",
    "                raise ValueError(f\"Missing name element\")\n",
    "            product_data['name'] = product_name\n",
    "\n",
    "            # 2. Extract price (updated handling)\n",
    "            price_element = card.find('span', class_='price-original-ER') or card.find('span', class_='price-limited-ER')\n",
    "            if not price_element:\n",
    "                raise ValueError(f\"Missing both price-original-ER and price-limited-ER elements\")\n",
    "            \n",
    "            try:\n",
    "                price_text = price_element.text.replace('S$', '').strip()\n",
    "                if '-' in price_text:\n",
    "                    min_price = min([float(p.strip()) for p in price_text.split('-')])\n",
    "                    product_data['price'] = min_price\n",
    "                else:\n",
    "                    product_data['price'] = float(price_text)\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Invalid price format: {price_element.text}\")\n",
    "\n",
    "            # 3. Extract image URL\n",
    "            img_tag = card.find('img', class_='thumb-img')\n",
    "            if not img_tag or 'src' not in img_tag.attrs:\n",
    "                raise ValueError(f\"Missing image URL\")\n",
    "            product_data['image_url'] = img_tag['src'].split('?')[0]\n",
    "\n",
    "            # 4. Extract product link\n",
    "            link_element = card.find('a')\n",
    "            if not link_element or 'href' not in link_element.attrs:\n",
    "                raise ValueError(f\"Missing product link\")\n",
    "            product_data['product_link'] = f'https://www.uniqlo.com{link_element[\"href\"]}'\n",
    "\n",
    "            # 5. Extract gender\n",
    "            gender_element = card.find('p', class_='product-tile-category-item-gender')\n",
    "            product_data['gender'] = 'U' if gender_element and 'UNISEX' in gender_element.text.upper() else 'M'\n",
    "\n",
    "            product_data.update({\n",
    "                'retailer': 'UNIQLO',\n",
    "                'category': 'Bottoms'\n",
    "            })\n",
    "\n",
    "            products.append(product_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            errors.append({\n",
    "                'index': index,\n",
    "                'name': product_name if 'product_name' in locals() else \"Unknown\",\n",
    "                'error': str(e)\n",
    "            })\n",
    "            continue\n",
    "    \n",
    "    return products, len(product_cards), errors\n",
    "\n",
    "def save_to_json(products, filename='products.json'):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(products, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with open('www.uniqlo.com_sg_en_men_bottoms.html', 'r', encoding='utf-8') as f:\n",
    "        html_content = f.read()\n",
    "    \n",
    "    products, total_count, errors = scrape_uniqlo(html_content)\n",
    "    save_to_json(products)\n",
    "    \n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(f\"Total products found: {total_count}\")\n",
    "    print(f\"Successfully processed: {len(products)}\")\n",
    "    print(f\"Skipped products: {total_count - len(products)}\\n\")\n",
    "    \n",
    "    if errors:\n",
    "        print(\"Detailed error report:\")\n",
    "        for error in errors:\n",
    "            print(f\"Product #{error['index']+1} ({error['name']}): {error['error']}\")\n",
    "    \n",
    "    print(\"\\nSaved valid products to products.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
